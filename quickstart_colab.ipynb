{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QhPWE1lwZHH"
      },
      "source": [
        "# Gemini API Python quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa7c47ae6451"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/quickstart_colab\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Google AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/quickstart_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/quickstart_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db29b8d4247e"
      },
      "source": [
        "This tutorial shows you how to get started with the Gemini API using the Python SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNg43Ymw54e"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You can run this tutorial in Google Colab, which doesn't require additional environment configuration.\n",
        "\n",
        "Alternatively, to complete this quickstart locally, see the Python guidance in [Get started with the Gemini API](https://ai.google.dev/tutorials/quickstart)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHkHARdb1ZID"
      },
      "source": [
        "## Install the SDK\n",
        "\n",
        "The Python SDK for the Gemini API is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "J6Pd9SFJ1yVi"
      },
      "outputs": [],
      "source": [
        "# The exclamation mark (!) lets you run shell commands directly inside a Jupyter/Colab notebook cell\n",
        "# 'pip install' is used to install Python packages\n",
        "# '-q' means quiet mode (reduces the amount of installation messages shown)\n",
        "# '-U' means upgrade to the latest version if the package is already installed\n",
        "# 'google-generativeai' is the package that provides access to Googleâ€™s Generative AI models (like Gemini)\n",
        "!pip install -q -U google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import packages**"
      ],
      "metadata": {
        "id": "C6TBKdkyLh7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pathlib module (used for handling filesystem paths in an object-oriented way)\n",
        "import pathlib\n",
        "\n",
        "# Import textwrap module (used to format and wrap text output neatly)\n",
        "import textwrap\n",
        "\n",
        "# Import the Google Generative AI package and give it the alias 'genai'\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Import Markdown and display functions from IPython.display\n",
        "# (used to render rich text like Markdown inside Jupyter/Colab notebooks)\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Import textwrap again (this is redundant because we already imported it above)\n",
        "import textwrap\n",
        "\n",
        "# Define a helper function to convert plain text into Markdown format\n",
        "def to_markdown(text):\n",
        "    # Replace all periods \".\" in the text with asterisks \"*\"\n",
        "    text = text.replace(\".\", \"*\")\n",
        "    # Return the text as Markdown, indenting each line with \">\"\n",
        "    # (predicate=True means apply indentation to every line)\n",
        "    return Markdown(textwrap.indent(text, \">\", predicate=lambda _: True))\n",
        "\n",
        "# --------------------- TEST EXAMPLE ---------------------\n",
        "# The following lines are commented out but show how to test the function:\n",
        "\n",
        "# Generate a response from the model by asking a question\n",
        "# response = model.generate_content(\"What is the meaning of life?\")\n",
        "\n",
        "# Display the response text in Markdown format using the helper function\n",
        "# display(to_markdown(response.text))\n"
      ],
      "metadata": {
        "id": "yWSIk9-8LltX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing 'userdata' module from Google Colab\n",
        "# 'userdata' allows you to securely store and access your secrets (like API keys, passwords, or tokens)\n",
        "# This way, you donâ€™t have to hardcode sensitive information directly in your notebook\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "WN5PRpS_NM5c"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeMCtmx9ykyx"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "\n",
        "<a class=\"button\" href=\"https://aistudio.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "HTiaTu6O1LRC"
      },
      "outputs": [],
      "source": [
        "# Import the Google Generative AI Python SDK\n",
        "# This SDK allows you to interact with Googleâ€™s generative AI models (like Gemini) from Python\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Import 'userdata' from Google Colab\n",
        "# 'userdata' lets you securely store and retrieve sensitive information like API keys\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the stored API key from Colab's secure storage\n",
        "# This assumes you have previously saved your Gemini API key under the name 'GOOGLE_API_KEY'\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Configure the GenAI client with your API key\n",
        "# This initializes the SDK so you can start making requests to the Gemini model\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Listing Models**"
      ],
      "metadata": {
        "id": "7RBYHZOSO4L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all the models available in your Google Generative AI account\n",
        "for m in genai.list_models():\n",
        "    # Check if the model supports the \"generateContent\" method\n",
        "    # \"generateContent\" means the model can generate text based on prompts\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        # Print the name of the model if it supports text generation\n",
        "        print(m.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "2CxFUqtgO7tz",
        "outputId": "a46559ae-1175-4ac3-b6f7-f7842ace1ea6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "s-JqXcDe2hZ_"
      },
      "outputs": [],
      "source": [
        "# Create an instance of a Generative AI model from Googleâ€™s Gemini series\n",
        "# 'genai.GenerativeModel' initializes the model so you can send prompts to it\n",
        "# 'gemini-1.5-flash' is the name of the model you want to use for text generation\n",
        "# You can replace it with other models that support 'generateContent' (see the previous list_models step)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXxypzJH4MUl"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time is a Jupyter/Colab magic command\n",
        "# It measures the time it takes to run the cell and prints it after execution\n",
        "%%time\n",
        "\n",
        "# Use the Gemini model instance to generate text content\n",
        "# 'generate_content()' sends a prompt to the model and returns the generated response\n",
        "# Here, the prompt asks the model: \"What are the key interview questions I can be asked in an interview as a data analyst\"\n",
        "response = model.generate_content(\n",
        "    \"What are the key interview questions i can be asked in an interview as a data analyst\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PxHrZPK4P9j-",
        "outputId": "35c88885-9fbc-47df-b1ea-8aa0ca09cb11"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 57.3 ms, sys: 9.39 ms, total: 66.7 ms\n",
            "Wall time: 8.16 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the text generated by the model into Markdown format\n",
        "# 'response.text' contains the text returned by the Gemini model\n",
        "# 'to_markdown()' is the helper function you defined earlier that:\n",
        "#   1) replaces periods with asterisks (*)\n",
        "#   2) indents each line with a \">\" for Markdown blockquote formatting\n",
        "# The result is a nicely formatted Markdown object that can be displayed in Colab\n",
        "from IPython.display import display\n",
        "\n",
        "display(to_markdown(response.text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wDVUJxtaQY-t",
        "outputId": "ca81ad30-e160-4427-a628-b8d995311093"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Data analyst interview questions can be broadly categorized into several areas*  Here's a breakdown of key question types, with examples:\n>\n>**I* Foundational Data Skills & Concepts:**\n>\n>* **SQL:** Expect questions testing your SQL proficiency*  This is crucial for most data analyst roles* Examples:\n>    * \"Write a query to find the top 5 customers with the highest total purchase value*\"\n>    * \"How would you optimize a slow-running SQL query?\"\n>    * \"Explain the difference between INNER JOIN, LEFT JOIN, and RIGHT JOIN*\"\n>    * \"How would you handle missing data in your SQL queries?\"\n>    * \"Explain different types of SQL indexes and when you would use them*\"\n>\n>* **Data Manipulation & Cleaning:**\n>    * \"Describe your experience with data cleaning and preprocessing*  Give an example of a time you had to handle messy data*\"\n>    * \"How would you handle outliers in a dataset?\"\n>    * \"What techniques do you use to identify and handle missing values?\"\n>    * \"How do you ensure data quality?\"\n>\n>* **Data Structures & Algorithms:**  While not as heavily emphasized as SQL, a basic understanding is helpful, especially for more senior roles*\n>    * \"What are the differences between a list and a dictionary in Python?\"\n>    * \"Explain the time and space complexity of a common algorithm (e*g*, sorting)*\"\n>    *  (May involve coding challenges for more senior roles)\n>\n>* **Statistics & Probability:**  A fundamental understanding is essential*\n>    * \"Explain the difference between correlation and causation*\"\n>    * \"What are the different types of sampling methods?\"\n>    * \"How would you interpret a p-value?\"\n>    * \"What are confidence intervals, and why are they important?\"\n>    * \"Explain different types of distributions (normal, binomial, Poisson)*\"\n>    * \"How would you test the significance of a difference between two group means?\"\n>\n>* **Data Visualization:**\n>    * \"What are your favorite data visualization tools?\" (e*g*, Tableau, Power BI, matplotlib, seaborn)\n>    * \"What are some best practices for creating effective visualizations?\"\n>    * \"How would you choose the right chart type for a given dataset and question?\"\n>    *  \"Describe a time you had to create a visualization to communicate a complex data story*\"\n>\n>**II* Analytical Skills & Problem-Solving:**\n>\n>* **Case Studies/Scenario-Based Questions:**  These are designed to assess your analytical thinking and problem-solving abilities*  Expect questions like:\n>    * \"A client wants to increase sales* How would you approach this problem using data analysis?\"\n>    * \"You notice a significant drop in website traffic* How would you investigate the cause?\"\n>    * \"How would you analyze the effectiveness of a marketing campaign?\"\n>\n>* **Business Acumen:**\n>    * \"How do you define a key performance indicator (KPI)?\"\n>    * \"What are some common KPIs used in [industry related to the job]?\"\n>    * \"How would you communicate your findings to a non-technical audience?\"\n>\n>* **Data Interpretation:**  You might be presented with charts, graphs, or tables and asked to interpret the data and draw conclusions*\n>\n>**III* Behavioral Questions (assessing soft skills):**\n>\n>* \"Tell me about a time you had to work with a large dataset*\"\n>* \"Describe a time you had to meet a tight deadline*\"\n>* \"Tell me about a time you faced a challenging analytical problem* How did you solve it?\"\n>* \"How do you handle conflicting priorities?\"\n>* \"Describe your experience working on a team*\"\n>* \"How do you stay up-to-date with the latest data analysis techniques and tools?\"\n>\n>\n>**IV* Technical Questions (depending on the role and seniority):**\n>\n>* **Programming Languages (Python, R):** Expect questions on data manipulation, data structures, libraries (pandas, NumPy, scikit-learn), and potentially coding challenges*\n>* **Machine Learning (for more advanced roles):**  Basic understanding of regression, classification, clustering, and model evaluation techniques*\n>* **Big Data Technologies (for specific roles):** Spark, Hadoop, etc*\n>* **Cloud Computing (AWS, Azure, GCP):**  Experience with cloud-based data warehousing or analysis tools*\n>\n>\n>**Preparation Tips:**\n>\n>* **Practice SQL queries:**  Work through numerous SQL problems on platforms like LeetCode, HackerRank, or Stratascratch*\n>* **Review statistical concepts:** Brush up on your statistics and probability knowledge*\n>* **Prepare case studies:** Practice answering scenario-based questions*  The STAR method (Situation, Task, Action, Result) is helpful for structuring your answers*\n>* **Build a portfolio:** Showcase your data analysis projects on platforms like GitHub or personal websites*\n>* **Research the company and role:** Understand the company's business and how data analysis contributes to its success*\n>\n>\n>Remember to tailor your preparation to the specific requirements and responsibilities outlined in the job description* Good luck!\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "j51mcrLD4Y2W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "274c99ca-67e0-43e8-a4e5-cb83691e751a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elara wasn't your typical twelve-year-old. While other kids obsessed over pop stars and social media, Elara dreamed of exploring forgotten ruins and uncovering lost civilizations.  Her mundane, grey backpack reflected her current reality â€“ a reality devoid of adventure. That was, until her eccentric Aunt Millie gifted her a backpack unlike any other.\n",
            "\n",
            "It was a patchwork thing, stitched together from mismatched fabrics, with brass buckles that gleamed even in the dimmest light.  Aunt Millie, with a twinkle in her eye, simply said, \"This, my dear, is a 'Whimsipack'.\"\n",
            "\n",
            "Elara scoffed. \"A what?\"\n",
            "\n",
            "\"A Whimsipack,\" Aunt Millie repeated, \"It takes you where your heart desires.\"\n",
            "\n",
            "Initially, Elara was skeptical. But that night, lying in bed, she wished, with all her might, to be in the Amazon rainforest.  The next morning, she found herself standing on damp earth, surrounded by the dense, humid air of the jungle.  Birds with plumage of impossible colours sang in the canopy above.  The Whimsipack, now seemingly larger, was nestled against a giant, moss-covered tree trunk.\n",
            "\n",
            "Over the next few weeks, Elara's life became an extraordinary blur.  She visited the Great Wall of China, rode a camel across the Sahara Desert, and even explored the lost city of Atlantis (though it turned out to be surprisingly mundane, mostly filled with seaweed and grumpy seahorses).  The Whimsipack, it turned out, wasn't just a portal, but a resourceful companion.  It magically produced appropriate clothing for each location, from sturdy hiking boots to flowing silk robes. It even provided food and water, although the quality was hit or miss (she still had nightmares about the glowing purple berries).\n",
            "\n",
            "But the Whimsipack had a mischievous side.  It wasn't just about destination; it was about the journey.  One day, wishing to see the Northern Lights, she found herself not in a cozy cabin, but clinging to the side of a runaway reindeer sleigh, being chased by a grumpy troll.  Another time, her wish for a pirate treasure led her to a deserted islandâ€¦where the treasure turned out to be a collection of remarkably well-preserved seashells.\n",
            "\n",
            "As exciting as her adventures were, Elara started to feel a little lonely.  She missed her friends, her family, even her boring, predictable life.  One day, she wished to be home.  The familiar grey walls of her bedroom greeted her, the Whimsipack lying quietly beside her bed.\n",
            "\n",
            "The adventures had changed her.  She learned about different cultures, faced her fears, and discovered an inner resilience she never knew she possessed.  The Whimsipack was still there, waiting for her next whim, but Elara understood something crucial.  Adventure wasn't just about exotic locales; it was about the courage to explore the world, both inside and out. And that, she knew, was a journey she could take anywhere, with or without a magical backpack.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.prompt_feedback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDGD5zC1TNZl",
        "outputId": "a38127a1-dc30-4ffd-a11d-97a3f86b54cf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quickstart_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}